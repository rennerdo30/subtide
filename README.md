# Subtide

<p align="center">
  <img src="extension/icons/icon128.png" width="128" height="128" alt="Subtide Logo">
</p>

<p align="center">
  <b>AI-powered video subtitle translation for YouTube, Twitch, and any video site.</b>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/version-1.1.0-blue.svg" alt="Version">
  <img src="https://img.shields.io/badge/license-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/python-3.9+-yellow.svg" alt="Python">
  <img src="https://img.shields.io/badge/chrome-MV3-blue.svg" alt="Chrome Extension">
</p>

---

## Features

### Core Translation
- **Real-time Translation** â€” Translate video subtitles on the fly
- **AI Transcription** â€” Generate subtitles with Whisper when none exist
- **Streaming Mode** â€” See subtitles within seconds, not minutes (Tier 4)
- **12+ Languages** â€” Support for major world languages
- **Context-Aware** â€” Merges partial sentences for better translation quality
- **Smart Caching** â€” Translations cached for instant replay

### Platform Support
- **YouTube** â€” Full support including embedded players
- **YouTube Shorts** â€” Pre-translation mode for instant subtitles while swiping
- **Twitch** â€” Live stream translation support
- **Generic Sites** â€” Works on any site with `<video>` elements

### User Experience
- **Modern UI** â€” Clean dark theme with teal accents
- **Draggable Subtitles** â€” Position subtitles anywhere on screen
- **Adjustable Size** â€” Small, Medium, Large, and XL subtitle options
- **Dual Subtitles** â€” Show original + translated text simultaneously
- **Keyboard Shortcuts** â€” Toggle subtitles (T), switch mode (D), download (S)
- **Subtitle Export** â€” Download as SRT, VTT, or TXT

### Technical
- **Flexible API** â€” Works with OpenAI, OpenRouter, or any OpenAI-compatible API
- **Local LLM Support** â€” Use LM Studio, Ollama, or other local models
- **Apple Silicon Optimized** â€” MLX Whisper backend for M1/M2/M3 Macs
- **GPU Acceleration** â€” CUDA support for NVIDIA GPUs

---

## Quick Start

### 1. Start the Backend

**Option A: Download Binary (Recommended)**

Download the latest backend binary from [Releases](https://github.com/rennerdo30/video-translate/releases):
- `video-translate-backend-linux`
- `video-translate-backend-macos`
- `video-translate-backend-windows.exe`

> **Prerequisite**: [FFmpeg](https://ffmpeg.org/download.html) must be installed.

```bash
# Make executable (Linux/macOS)
chmod +x video-translate-backend-macos

# Run
./video-translate-backend-macos
```

**Option B: Run from Source**

```bash
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
./run.sh
```

**Option C: Docker**

```bash
cd backend
docker-compose up video-translate-tier2
```

### 2. Install the Extension

1. Open Chrome â†’ `chrome://extensions`
2. Enable **Developer mode**
3. Click **Load unpacked** â†’ select the `extension` folder
4. Pin the extension to your toolbar

### 3. Configure

1. Click the extension icon
2. Select your operation mode (see [Operation Modes](#operation-modes))
3. Enter your API key and model (for Tier 1 & 2)
4. Choose your target language
5. Save configuration

### 4. Translate!

**YouTube Videos:**
1. Go to any YouTube video
2. Click the translate button in the player controls
3. Subtitles appear automatically

**YouTube Shorts:**
1. Navigate to any Shorts video
2. Click the floating translate button (bottom-right)
3. Enable translation â€” videos are pre-translated as you scroll
4. Subtitles appear instantly when swiping to the next Short

---

## Operation Modes

This project is fully open-source with no paid tiers. The "Tiers" refer to different technical configurations:

| Feature | Tier 1 | Tier 2 | Tier 3 | Tier 4 |
|---------|--------|--------|--------|--------|
| YouTube Captions | âœ… | âœ… | âœ… | âœ… |
| Whisper Transcription | âŒ | âœ… | âœ… | âœ… |
| API Key Location | Browser | Browser | Server | Server |
| Force AI Generation | âŒ | âœ… | âœ… | âœ… |
| Progressive Streaming | âŒ | âŒ | âŒ | âœ… |

- **Tier 1 (Standard)** â€” Uses existing YouTube captions + your API key
- **Tier 2 (Enhanced)** â€” Whisper transcription + your API key
- **Tier 3 (Managed)** â€” Server handles API keys (for shared deployments)
- **Tier 4 (Stream)** â€” Progressive translation with instant subtitle display

---

## YouTube Shorts Mode

Shorts are consumed rapidly (swipe behavior), so on-demand translation is too slow. Shorts mode uses **pre-translation**:

1. **Detection** â€” Automatically detects all Shorts in your feed
2. **Pre-translation** â€” Translates 4+ videos ahead in the background
3. **Instant Display** â€” Cached subtitles appear immediately when you swipe

### Shorts Controls
- **Toggle Button** â€” Floating button (bottom-right) to enable/disable
- **Language Selection** â€” Quick language picker in dropdown
- **Size Adjustment** â€” S / M / L / XL subtitle sizes
- **Draggable Subtitles** â€” Drag to reposition, double-click to reset
- **Queue Status** â€” Shows translation progress in real-time

---

## Supported Languages

| Language | Code | Language | Code |
|----------|------|----------|------|
| ğŸ‡¬ğŸ‡§ English | `en` | ğŸ‡¯ğŸ‡µ Japanese | `ja` |
| ğŸ‡ªğŸ‡¸ Spanish | `es` | ğŸ‡°ğŸ‡· Korean | `ko` |
| ğŸ‡«ğŸ‡· French | `fr` | ğŸ‡¨ğŸ‡³ Chinese (Simplified) | `zh-CN` |
| ğŸ‡©ğŸ‡ª German | `de` | ğŸ‡¹ğŸ‡¼ Chinese (Traditional) | `zh-TW` |
| ğŸ‡µğŸ‡¹ Portuguese | `pt` | ğŸ‡¸ğŸ‡¦ Arabic | `ar` |
| ğŸ‡·ğŸ‡º Russian | `ru` | ğŸ‡®ğŸ‡³ Hindi | `hi` |
| ğŸ‡®ğŸ‡¹ Italian | `it` | | |

---

## Docker Deployment

```bash
cd backend

# Tier 1: Standard (YouTube captions only)
docker-compose up video-translate-tier1

# Tier 2: With Whisper transcription
docker-compose up video-translate-tier2

# Tier 3/4: Managed with server-side API key
SERVER_API_KEY=sk-xxx docker-compose up video-translate-tier3
```

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `PORT` | Server port | `5001` |
| `GUNICORN_WORKERS` | Number of workers | `2` |
| `GUNICORN_TIMEOUT` | Request timeout (seconds) | `300` |
| `CORS_ORIGINS` | Allowed origins (`*` for all) | `*` |
| `SERVER_API_KEY` | API key for Tier 3/4 | â€” |
| `SERVER_API_URL` | LLM API endpoint | â€” |
| `SERVER_MODEL` | LLM model name | â€” |
| `WHISPER_MODEL` | Whisper model size | `base` |
| `WHISPER_BACKEND` | `mlx`, `faster`, or `openai` | auto-detected |

---

## Cloud Deployment (RunPod)

For GPU-accelerated transcription, deploy on [RunPod.io](https://runpod.io):

```bash
docker pull ghcr.io/rennerdo30/video-translate-runpod:latest
```

Configure the extension with your RunPod endpoint:
- **Serverless**: `https://api.runpod.ai/v2/{ENDPOINT_ID}`
- **Dedicated**: `https://pod-id-5001.proxy.runpod.net`

See [backend/RUNPOD.md](backend/RUNPOD.md) for complete instructions.

---

## Local LLM Setup

Run translations completely locally using LM Studio or Ollama.

### LM Studio

1. Download [LM Studio](https://lmstudio.ai/)
2. Download a model (e.g., Llama 3.1 8B)
3. Start the local server (default: `http://localhost:1234/v1`)
4. Configure extension:
   - **Provider**: Custom Endpoint
   - **API URL**: `http://localhost:1234/v1`
   - **API Key**: `lm-studio`

### Ollama

1. Install [Ollama](https://ollama.ai/)
2. Pull a model: `ollama pull llama3.1:8b`
3. Configure extension:
   - **Provider**: Custom Endpoint
   - **API URL**: `http://localhost:11434/v1`
   - **API Key**: `ollama`

### Recommended Models

| Model | Size | Quality | Speed | Best For |
|-------|------|---------|-------|----------|
| `llama3.1:8b` | 4.7 GB | Good | Fast | Most users |
| `mistral:7b` | 4.1 GB | Good | Fast | General use |
| `qwen2.5:7b` | 4.4 GB | Excellent | Fast | Asian languages |
| `command-r:35b-q4` | 20 GB | Excellent | Medium | Multilingual |

---

## Hardware Requirements

### Apple Silicon (Unified Memory)

| Mac | Memory | Whisper | LLM | Notes |
|-----|--------|---------|-----|-------|
| M1/M2 (8GB) | 8 GB | tiny/base | âŒ | Not recommended |
| M1/M2 (16GB) | 16 GB | small | Llama 3.1 8B | Comfortable |
| M1/M2 Pro (32GB) | 32 GB | large-v3 | Llama 3.1 8B | Full quality |
| M1/M2 Max (64GB) | 64 GB | large-v3 | Llama 3.1 70B | Best local |

**Recommended**: `WHISPER_BACKEND=mlx` with `large-v3-turbo`

### NVIDIA GPUs

| GPU | VRAM | Whisper | LLM |
|-----|------|---------|-----|
| RTX 3060 | 12 GB | medium | Llama 3.1 8B |
| RTX 3090/4080 | 16-24 GB | large-v3 | Llama 3.1 8B |
| RTX 4090 | 24 GB | large-v3 | Llama 3.1 13B |

**Recommended**: `WHISPER_BACKEND=faster` with `large-v3`

---

## Architecture

```
video-translate/
â”œâ”€â”€ backend/                    # Python Flask server
â”‚   â”œâ”€â”€ app.py                  # Entry point
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ translation.py      # API endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ whisper_service.py  # Speech-to-text
â”‚   â”‚   â”œâ”€â”€ translation_service.py  # LLM translation
â”‚   â”‚   â”œâ”€â”€ youtube_service.py  # YouTube data extraction
â”‚   â”‚   â””â”€â”€ process_service.py  # Pipeline orchestration
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ model_utils.py      # Model management
â”‚   â”‚   â”œâ”€â”€ partial_cache.py    # Translation caching
â”‚   â”‚   â””â”€â”€ language_detection.py  # Language utilities
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ extension/                  # Chrome Extension (MV3)
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ _locales/               # i18n translations
â”‚   â”œâ”€â”€ icons/                  # App icons
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ background/
â”‚       â”‚   â””â”€â”€ service-worker.js   # Background tasks, Shorts queue
â”‚       â”œâ”€â”€ content/
â”‚       â”‚   â”œâ”€â”€ youtube.js          # YouTube integration
â”‚       â”‚   â”œâ”€â”€ youtube-shorts.js   # Shorts pre-translation
â”‚       â”‚   â”œâ”€â”€ youtube-subtitles.js # Subtitle rendering
â”‚       â”‚   â”œâ”€â”€ youtube-ui.js       # UI controls
â”‚       â”‚   â”œâ”€â”€ youtube-styles.js   # CSS injection
â”‚       â”‚   â”œâ”€â”€ twitch.js           # Twitch integration
â”‚       â”‚   â”œâ”€â”€ generic.js          # Generic video support
â”‚       â”‚   â””â”€â”€ shorts-interceptor.js # Shorts feed detection
â”‚       â”œâ”€â”€ lib/
â”‚       â”‚   â””â”€â”€ debug.js            # Logging utilities
â”‚       â”œâ”€â”€ offscreen/              # Audio capture
â”‚       â””â”€â”€ popup/                  # Extension popup
â”‚           â”œâ”€â”€ popup.html
â”‚           â””â”€â”€ popup.js
â”‚
â”œâ”€â”€ SPECIFICATION.md            # Detailed technical spec
â”œâ”€â”€ CONTRIBUTING.md             # Contribution guide
â””â”€â”€ LICENSE                     # MIT License
```

---

## Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `T` | Toggle subtitles on/off |
| `D` | Toggle dual subtitle mode |
| `S` | Download subtitles |

---

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/api/translate` | POST | Translate video (batch) |
| `/api/stream` | POST | Translate video (streaming) |
| `/api/status/{id}` | GET | Check translation status |

---

## Troubleshooting

### Backend Connection Issues

**"Cannot connect to backend" / "Network Error"**
- Verify the backend is running: `curl http://localhost:5001/health`
- Check if another application is using port 5001
- Ensure your firewall allows connections on port 5001
- For Docker: verify the container is running with `docker ps`

**CORS Errors in Browser Console**
- Set `CORS_ORIGINS=*` in your environment or `.env` file
- Restart the backend after changing CORS settings

### FFmpeg Issues

**"FFmpeg not found" / Audio extraction fails**
- Install FFmpeg:
  - macOS: `brew install ffmpeg`
  - Ubuntu/Debian: `sudo apt install ffmpeg`
  - Windows: `choco install ffmpeg` or download from [ffmpeg.org](https://ffmpeg.org/download.html)
- Verify installation: `ffmpeg -version`
- Ensure FFmpeg is in your system PATH

### Whisper / Transcription Issues

**Out of memory errors**
- Use a smaller model: `WHISPER_MODEL=base` or `WHISPER_MODEL=tiny`
- Model memory requirements:
  - `tiny`: ~1 GB
  - `base`: ~1 GB
  - `small`: ~2 GB
  - `medium`: ~5 GB
  - `large-v3`: ~10 GB

**Slow transcription**
- On Apple Silicon: ensure `WHISPER_BACKEND=mlx` is set
- On NVIDIA GPU: ensure `WHISPER_BACKEND=faster` and CUDA is installed
- Consider using `large-v3-turbo` for faster processing with similar quality

**"No module named 'mlx'" (Apple Silicon)**
- MLX only works on Apple Silicon Macs
- Install with: `pip install mlx-whisper`

### Extension Issues

**Extension not loading**
- Ensure Developer mode is enabled in `chrome://extensions`
- Check for errors in the extension card
- Try removing and re-adding the extension

**Subtitles not appearing**
- Click the translate button in the player controls
- Check the extension popup for error messages
- Verify the backend URL is correct in settings
- Check browser console (F12) for errors

**YouTube controls not showing translate button**
- Refresh the page
- Disable other extensions that modify YouTube's interface
- Clear browser cache and reload

### Docker Issues

**Container exits immediately**
- Check logs: `docker logs <container_id>`
- Verify port mapping: `-p 5001:5001`
- Ensure sufficient memory is allocated to Docker

**"Permission denied" errors**
- On Linux, you may need to run with `sudo` or add your user to the docker group

### API Key Issues

**"Invalid API key" / 401 errors**
- Verify your API key is correct and has not expired
- Check that you're using the correct API URL for your provider
- For local LLMs (LM Studio, Ollama), use any non-empty string as the API key

---

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for development setup and guidelines.

---

## License

MIT License - See [LICENSE](LICENSE) for details.

---

## Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) â€” Speech recognition
- [MLX Whisper](https://github.com/ml-explore/mlx-examples) â€” Apple Silicon optimization
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) â€” Video data extraction
- [Flask](https://flask.palletsprojects.com/) â€” Backend framework
